#!/usr/bin/env python3
"""
Script de v√©rification des optimisations GPU Blackwell pour ComfyUI
Compatible PyTorch 2.8.0 + CUDA 12.9 - Ce script v√©rifie que toutes les optimisations sont correctement activ√©es
"""

import sys
import torch
import subprocess
import os
from typing import Dict, List, Tuple

def check_torch_version() -> Tuple[bool, str]:
    """V√©rifier la version de PyTorch"""
    torch_version = torch.__version__
    required_version = "2.8.0"
    
    if torch_version >= required_version:
        return True, f"‚úÖ PyTorch {torch_version} (>= {required_version})"
    else:
        return False, f"‚ùå PyTorch {torch_version} (< {required_version} requis)"

def check_cuda_version() -> Tuple[bool, str]:
    """V√©rifier la version de CUDA"""
    if not torch.cuda.is_available():
        return False, "‚ùå CUDA non disponible"
    
    cuda_version = torch.version.cuda
    required_version = "12.9"
    
    if cuda_version and cuda_version >= required_version:
        return True, f"‚úÖ CUDA {cuda_version} (>= {required_version})"
    else:
        return False, f"‚ùå CUDA {cuda_version or 'Unknown'} (< {required_version} requis)"

def check_gpu_architecture() -> Tuple[bool, str]:
    """V√©rifier l'architecture GPU et support Blackwell"""
    if not torch.cuda.is_available():
        return False, "‚ùå CUDA non disponible"
    
    gpu_name = torch.cuda.get_device_name(0)
    gpu_capability = torch.cuda.get_device_capability(0)
    
    # Blackwell a une compute capability de 9.0
    if gpu_capability[0] >= 9:
        return True, f"‚úÖ GPU Blackwell d√©tect√©: {gpu_name} (Compute {gpu_capability[0]}.{gpu_capability[1]})"
    elif gpu_capability[0] >= 8:
        return True, f"‚úÖ GPU moderne d√©tect√©: {gpu_name} (Compute {gpu_capability[0]}.{gpu_capability[1]})"
    else:
        return False, f"‚ö†Ô∏è GPU ancien: {gpu_name} (Compute {gpu_capability[0]}.{gpu_capability[1]})"

def check_environment_variables() -> List[Tuple[bool, str]]:
    """V√©rifier les variables d'environnement d'optimisation"""
    # Variables d'optimisation critiques pour GPU
    critical_optimizations = [
        ("TORCH_CUDA_ARCH_LIST", "9.0+PTX", "Architecture Blackwell support√©e"),
        ("CUDA_MODULE_LOADING", "LAZY", "Chargement CUDA optimis√©"),
        ("TORCH_CUDNN_V8_API_ENABLED", "1", "CuDNN v8 API activ√©e"),
        ("PYTORCH_CUDA_ALLOC_CONF", "expandable_segments:True", "Allocation m√©moire optimis√©e"),
        ("CUBLAS_WORKSPACE_CONFIG", ":4096:8", "Configuration CUBLAS optimis√©e"),
        ("HF_HUB_ENABLE_HF_TRANSFER", "1", "Transfert HuggingFace optimis√©"),
        ("TORCH_COMPILE_MODE", "default", "Mode de compilation PyTorch"),
        ("TORCH_NCCL_AVOID_RECORD_STREAMS", "1", "Optimisation NCCL streams"),
        ("PYTORCH_JIT_USE_NNC_NOT_NVFUSER", "0", "Configuration JIT optimis√©e"),
    ]
    
    # Variables d'environnement g√©n√©rales
    general_variables = [
        ("PYTHONUNBUFFERED", "1", "Sortie Python non tamponn√©e"),
        ("PIP_NO_CACHE_DIR", "1", "Cache pip d√©sactiv√©"),
        ("DEBIAN_FRONTEND", "noninteractive", "Installation Debian non interactive"),
    ]
    
    results = []
    
    # V√©rification des optimisations critiques
    for var_name, expected_contains, description in critical_optimizations:
        var_value = os.environ.get(var_name, "")
        if expected_contains in var_value:
            results.append((True, f"‚úÖ {description}: {var_name}={var_value}"))
        else:
            results.append((False, f"‚ùå {description}: {var_name}={var_value or 'Non d√©finie'}"))
    
    # V√©rification des variables g√©n√©rales (moins critiques)
    for var_name, expected_value, description in general_variables:
        var_value = os.environ.get(var_name, "")
        if var_value == expected_value:
            results.append((True, f"‚úÖ {description}: {var_name}={var_value}"))
        elif var_value:
            results.append((True, f"‚ö†Ô∏è {description}: {var_name}={var_value} (valeur diff√©rente mais d√©finie)"))
        else:
            results.append((False, f"‚ùå {description}: {var_name} non d√©finie"))
    
    return results

def check_cuda_architecture_support() -> Tuple[bool, str]:
    """V√©rifier sp√©cifiquement le support des architectures CUDA"""
    cuda_arch_list = os.environ.get("TORCH_CUDA_ARCH_LIST", "")
    
    if not cuda_arch_list:
        return False, "‚ùå TORCH_CUDA_ARCH_LIST non d√©finie"
    
    # V√©rifier le support Blackwell (9.0) et la r√©trocompatibilit√© (8.6)
    has_blackwell = "9.0+PTX" in cuda_arch_list
    has_ampere = "8.6+PTX" in cuda_arch_list
    
    if has_blackwell and has_ampere:
        return True, f"‚úÖ Support complet: Blackwell (9.0) + Ampere (8.6): {cuda_arch_list}"
    elif has_blackwell:
        return True, f"‚úÖ Support Blackwell d√©tect√©: {cuda_arch_list}"
    elif has_ampere:
        return False, f"‚ö†Ô∏è Support Ampere uniquement (pas de Blackwell): {cuda_arch_list}"
    else:
        return False, f"‚ùå Architecture CUDA non optimis√©e: {cuda_arch_list}"

def check_pytorch_memory_optimization() -> Tuple[bool, str]:
    """V√©rifier les optimisations m√©moire PyTorch"""
    alloc_conf = os.environ.get("PYTORCH_CUDA_ALLOC_CONF", "")
    
    if not alloc_conf:
        return False, "‚ùå PYTORCH_CUDA_ALLOC_CONF non d√©finie"
    
    has_expandable = "expandable_segments:True" in alloc_conf
    has_roundup = "roundup_power2_divisions" in alloc_conf
    
    if has_expandable and has_roundup:
        return True, f"‚úÖ Optimisations m√©moire compl√®tes: {alloc_conf}"
    elif has_expandable:
        return True, f"‚úÖ Segments extensibles activ√©s: {alloc_conf}"
    else:
        return False, f"‚ùå Optimisations m√©moire manquantes: {alloc_conf}"

def check_flash_attention() -> Tuple[bool, str]:
    """V√©rifier la disponibilit√© de Flash Attention"""
    try:
        import flash_attn
        return True, f"‚úÖ Flash Attention disponible (v{flash_attn.__version__})"
    except ImportError:
        return False, "‚ùå Flash Attention non install√©e"

def check_xformers() -> Tuple[bool, str]:
    """V√©rifier la disponibilit√© de xFormers"""
    try:
        import xformers
        return True, f"‚úÖ xFormers disponible (v{xformers.__version__})"
    except ImportError:
        return False, "‚ùå xFormers non install√©"

def check_triton() -> Tuple[bool, str]:
    """V√©rifier la disponibilit√© de Triton"""
    try:
        import triton
        return True, f"‚úÖ Triton disponible (v{triton.__version__})"
    except ImportError:
        return False, "‚ùå Triton non install√©"

def check_torch_compile() -> Tuple[bool, str]:
    """V√©rifier les optimisations torch.compile"""
    try:
        # Test simple de torch.compile
        @torch.compile
        def test_function(x):
            return x * 2
        
        if torch.cuda.is_available():
            x = torch.randn(10, device='cuda')
            result = test_function(x)
            return True, "‚úÖ torch.compile fonctionnel"
        else:
            return False, "‚ùå CUDA requis pour torch.compile"
    except Exception as e:
        return False, f"‚ùå torch.compile non fonctionnel: {str(e)}"

def main():
    """Fonction principale"""
    print("üîç V√©rification des optimisations GPU Blackwell pour ComfyUI")
    print("=" * 60)
    print()
    
    # Affichage des informations syst√®me importantes
    print("üìã Informations syst√®me:")
    print(f"  ‚Ä¢ Python: {sys.version.split()[0]}")
    print(f"  ‚Ä¢ PyTorch: {torch.__version__}")
    if torch.cuda.is_available():
        print(f"  ‚Ä¢ CUDA: {torch.version.cuda}")
        print(f"  ‚Ä¢ GPU: {torch.cuda.get_device_name(0)}")
        print(f"  ‚Ä¢ Compute Capability: {'.'.join(map(str, torch.cuda.get_device_capability(0)))}")
    else:
        print("  ‚Ä¢ CUDA: Non disponible")
    print()
    
    all_checks_passed = True
    
    # V√©rifications principales
    checks = [
        ("Version PyTorch", check_torch_version),
        ("Version CUDA", check_cuda_version), 
        ("Architecture GPU", check_gpu_architecture),
        ("Support Architecture CUDA", check_cuda_architecture_support),
        ("Optimisations M√©moire PyTorch", check_pytorch_memory_optimization),
        ("Flash Attention", check_flash_attention),
        ("xFormers", check_xformers),
        ("Triton", check_triton),
        ("torch.compile", check_torch_compile),
    ]
    
    for check_name, check_func in checks:
        try:
            success, message = check_func()
            print(f"{check_name}: {message}")
            if not success:
                all_checks_passed = False
        except Exception as e:
            print(f"{check_name}: ‚ùå Erreur - {str(e)}")
            all_checks_passed = False
    
    print()
    print("üîß Variables d'environnement d'optimisation:")
    print("-" * 50)
    env_results = check_environment_variables()
    env_critical_failed = 0
    env_general_failed = 0
    
    for success, message in env_results:
        print(f"  {message}")
        if not success:
            if "‚ùå" in message:
                if any(critical in message for critical in ["TORCH_", "CUDA_", "PYTORCH_", "CUBLAS_"]):
                    env_critical_failed += 1
                else:
                    env_general_failed += 1
                all_checks_passed = False
    
    print()
    if env_critical_failed > 0:
        print(f"‚ö†Ô∏è {env_critical_failed} variable(s) d'optimisation critique(s) manquante(s)")
    if env_general_failed > 0:
        print(f"‚ÑπÔ∏è {env_general_failed} variable(s) g√©n√©rale(s) non configur√©e(s) (non critique)")
    
    print()
    print("=" * 60)
    
    if all_checks_passed:
        print("üéâ Toutes les optimisations Blackwell sont correctement configur√©es!")
        print("‚úÖ Votre environnement est optimal pour les GPU Blackwell.")
        sys.exit(0)
    else:
        print("‚ö†Ô∏è Certaines optimisations ne sont pas configur√©es correctement.")
        print("üìñ Actions recommand√©es:")
        print("   ‚Ä¢ V√©rifiez les variables d'environnement manquantes")
        print("   ‚Ä¢ Consultez le Dockerfile pour les configurations recommand√©es")
        print("   ‚Ä¢ Red√©marrez le conteneur si n√©cessaire")
        sys.exit(1)

if __name__ == "__main__":
    main()
